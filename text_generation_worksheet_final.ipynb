{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-generation-worksheet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKcucuNNx1Wxgvr5GV+EqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magdapoppins/RNN-workshop/blob/main/text_generation_worksheet_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ7yqMKpZhNx"
      },
      "source": [
        "# Study Project - Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82uZpfL5Fego"
      },
      "source": [
        "### Our project plan\n",
        "0. Import the required libraries\n",
        "1. Fetch the text data\n",
        "2. Create a mapping from unique characters to integers\n",
        "3. Transform the dataset into patterns of a specified length with a label-value mapping \n",
        "4. Reshape the inputs to contain the samples, the time step count and features\n",
        "5. Normalize the inputs\n",
        "6. One hot encode the output variables\n",
        "7. Define the LSTM model \n",
        "8. Define our checkpoints\n",
        "9. Fit the model (go get a coffee)\n",
        "10. Use the model to generate some output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY_XE6HgkpX1"
      },
      "source": [
        "## Install the required libraries\n",
        "- numpy\n",
        "- Sequential from tensorflow.keras.models\n",
        "- Dense, Dropout and LSTM from tensorflow.keras.layers\n",
        "- ModelCheckpoint from tensorflow.keras.callbacks\n",
        "- tensorflow.keras.utils as utils\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER4-pBicBirU"
      },
      "source": [
        "import numpy \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow.keras.utils as utils"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z52XEju-A6N9"
      },
      "source": [
        "## Uploading the data\n",
        "- Download your book of choice as a .txt file\n",
        "- Edit out the Gutenberg preamble and table of contents\n",
        "- Upload the resulted file here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUIOfAL72mAP"
      },
      "source": [
        "## Get the data into the notebook\n",
        "1. Create a variable `filename` to hold the name of your text file.\n",
        "2. Use `open()` with the filename, mode 'r' (read), and encoding utf-8 combined with `read()` to get the raw text. Save the raw text in a variable.\n",
        "3. Transform the raw text into lowercase.\n",
        "4. Print the character length of the text.  \n",
        "5. BONUS: Replace rare characters (á, é, ï and similar with more common ones like a, e, i)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGRiVEElwN_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3ce424-642a-4a1f-9010-c42893a10ffd"
      },
      "source": [
        "filename = \"frankenstein.txt\"\n",
        "raw_text = open(filename, 'r', encoding=\"utf-8\").read()\n",
        "raw_text = raw_text.lower()\n",
        "print(\"Total count of characters: \", len(raw_text))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total count of characters:  437493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NORo7MGvwa4_"
      },
      "source": [
        "### Truncate the input (optional)\n",
        "For testing purposes you might want to shorten your character count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aujUtZx2k1yJ"
      },
      "source": [
        "#raw_text = raw_text[:500000]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk9mhw0N4T8N"
      },
      "source": [
        "Print the first 1000 characters of your text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoqYGTSwloah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3371e2-9a9f-4812-c043-6f6be73f999c"
      },
      "source": [
        "print(raw_text[:1000])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "letter 1\n",
            "\n",
            "_to mrs. saville, england._\n",
            "\n",
            "\n",
            "st. petersburgh, dec. 11th, 17—.\n",
            "\n",
            "\n",
            "you will rejoice to hear that no disaster has accompanied the\n",
            "commencement of an enterprise which you have regarded with such evil\n",
            "forebodings. i arrived here yesterday, and my first task is to assure\n",
            "my dear sister of my welfare and increasing confidence in the success\n",
            "of my undertaking.\n",
            "\n",
            "i am already far north of london, and as i walk in the streets of\n",
            "petersburgh, i feel a cold northern breeze play upon my cheeks, which\n",
            "braces my nerves and fills me with delight. do you understand this\n",
            "feeling? this breeze, which has travelled from the regions towards\n",
            "which i am advancing, gives me a foretaste of those icy climes.\n",
            "inspirited by this wind of promise, my daydreams become more fervent\n",
            "and vivid. i try in vain to be persuaded that the pole is the seat of\n",
            "frost and desolation; it ever presents itself to my imagination as the\n",
            "region of beauty and delight. there, margaret, the sun is for ever\n",
            "visible, its broad dis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvXWc6tO4bH6"
      },
      "source": [
        "Create a variable `vocabulary` to hold a set of unique characters in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq6Os53MlqdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e226790-0efa-4a92-b35f-551004b6635c"
      },
      "source": [
        "vocabulary = sorted(set(raw_text))\n",
        "print(len(vocabulary))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9OeO_uBzTyu"
      },
      "source": [
        "## Create a mapping from the unique characters to integers\n",
        "1. Use a dict comprehension and `enumerate` to create a dictionary `character_to_integer` where the key is the character and the value is a integer (the iterator). \n",
        "2. Print the resulted dictionary (you can import and use pprint to make it more readable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CP2GXQ-zZPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd231daa-6b16-487a-9fba-98c20ed616f5"
      },
      "source": [
        "from pprint import pprint\n",
        "character_to_integer = dict((c, i) for i, c in enumerate(vocabulary))\n",
        "pprint(character_to_integer)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0,\n",
            " ' ': 1,\n",
            " '!': 2,\n",
            " '\"': 3,\n",
            " '$': 4,\n",
            " '%': 5,\n",
            " \"'\": 6,\n",
            " '(': 7,\n",
            " ')': 8,\n",
            " '*': 9,\n",
            " ',': 10,\n",
            " '-': 11,\n",
            " '.': 12,\n",
            " '/': 13,\n",
            " '0': 14,\n",
            " '1': 15,\n",
            " '2': 16,\n",
            " '3': 17,\n",
            " '4': 18,\n",
            " '5': 19,\n",
            " '6': 20,\n",
            " '7': 21,\n",
            " '8': 22,\n",
            " '9': 23,\n",
            " ':': 24,\n",
            " ';': 25,\n",
            " '?': 26,\n",
            " '[': 27,\n",
            " ']': 28,\n",
            " '_': 29,\n",
            " 'a': 30,\n",
            " 'b': 31,\n",
            " 'c': 32,\n",
            " 'd': 33,\n",
            " 'e': 34,\n",
            " 'f': 35,\n",
            " 'g': 36,\n",
            " 'h': 37,\n",
            " 'i': 38,\n",
            " 'j': 39,\n",
            " 'k': 40,\n",
            " 'l': 41,\n",
            " 'm': 42,\n",
            " 'n': 43,\n",
            " 'o': 44,\n",
            " 'p': 45,\n",
            " 'q': 46,\n",
            " 'r': 47,\n",
            " 's': 48,\n",
            " 't': 49,\n",
            " 'u': 50,\n",
            " 'v': 51,\n",
            " 'w': 52,\n",
            " 'x': 53,\n",
            " 'y': 54,\n",
            " 'z': 55,\n",
            " 'æ': 56,\n",
            " 'è': 57,\n",
            " 'é': 58,\n",
            " 'ê': 59,\n",
            " 'ô': 60,\n",
            " '—': 61,\n",
            " '‘': 62,\n",
            " '’': 63,\n",
            " '“': 64,\n",
            " '”': 65}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1ygDAzbHNjo"
      },
      "source": [
        "## Transforming the data into inputs and outputs\n",
        "Let's summarize our data by checking\n",
        "- how many characters is our text in total?\n",
        "- how many unique characters are there?\n",
        "\n",
        "Save both counts in variables `n_characters` and `n_vocabulary`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgMP4szK0y4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a57768-b7f2-4539-e799-dda83719222b"
      },
      "source": [
        "n_characters = len(raw_text)\n",
        "n_vocabulary = len(vocabulary)\n",
        "print(\"Total characters: \", n_characters)\n",
        "print(\"Total vocabulary: \", n_vocabulary)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total characters:  437493\n",
            "Total vocabulary:  66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5xWxh7h2s0B"
      },
      "source": [
        "Creating the inputs and outputs:\n",
        "1. Define a variable `sequence_length` and give it the value 100\n",
        "2. Define empty lists dataX and dataY\n",
        "3. Loop over the range `n_characters - sequence_length` using the iterator i\n",
        "  - Define a variable `sequence_input` which is the text from index i until index i + `sequence_length`\n",
        "  - Define a variable `sequence_output` which is the character in the text at position `i + sequence_length`\n",
        "  - Transform `sequence_input` to integers and append it to `dataX`\n",
        "  - Transform `sequence_output` to an integer and append it to `dataY`\n",
        "4. Print the length of dataX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHM0jUj4HwbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdc74b7-49a3-411e-d550-89d8ab92987e"
      },
      "source": [
        "sequence_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(n_characters - sequence_length):\n",
        "  sequence_input = raw_text[i:i + sequence_length]\n",
        "  sequence_output = raw_text[i + sequence_length]\n",
        "  dataX.append([character_to_integer[char] for char in sequence_input])\n",
        "  dataY.append(character_to_integer[sequence_output])\n",
        "\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total patterns: \", n_patterns)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total patterns:  437393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnuhNvAL3Nws"
      },
      "source": [
        "## Reshape our inputs \n",
        "Create a new variable X that will hold the result of `numpy.reshape` on dataX with the new shape `(length of dataX, length of a sequence, features (1))`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtGjnzrg3Qzw"
      },
      "source": [
        "X = numpy.reshape(dataX, (n_patterns, sequence_length, 1))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71Z1dZHR4j-8"
      },
      "source": [
        "## Normalize the inputs\n",
        "Update X to be X divided by our vocabulary count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4frkB7C74lpA"
      },
      "source": [
        "X = X / float(n_vocabulary)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBny8KHL4nzi"
      },
      "source": [
        "## One hot encode the outputs\n",
        "Define a new variable y that contains dataY one hot encoded using `utils.to_categorical`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KA_HjUJ46L9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ca252b-0a01-42fc-c3f6-382219f2c775"
      },
      "source": [
        "y = utils.to_categorical(dataY)\n",
        "print(y[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNgchGVTKSzf"
      },
      "source": [
        "## Designing the model\n",
        "1. Define a variable model that is an empty `Sequential`\n",
        "2. Add an LSTM layer with 256 units, and the input shape `(X.shape[1], X.shape[2])` \n",
        "3. Add a dropout layer with dropout rate .2\n",
        "4. Add a dense layer with `y.shape[1]` units and a softmax activation\n",
        "5. Compile the model using `categorical_crossentropy` as the loss and an adam optimizer\n",
        "6. Print the model summary\n",
        "7. BONUS: Add an extra LSTM and Dropout layer for improved results (this takea longer to train) - in this case you only need to tell the following LSTM layer the count of memory units. You also need to add \"return_sequences=True\" to the first LSTM layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_9btTKL5zhR"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g1_phjTu_E0",
        "outputId": "d52c88c9-7547-45c4-e01c-43dd4156b6b5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 66)                16962     \n",
            "=================================================================\n",
            "Total params: 806,466\n",
            "Trainable params: 806,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiAtWXq-6Rsq"
      },
      "source": [
        "## Define checkpoints\n",
        "1. Define a variable `filepath` for a hdf5 file containing the epoch and loss, e.g. `\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"`\n",
        "2. Define a variable `checkpoint` to hold an instance of ModelCheckpoint for that filepath, where monitor='loss', save_best_only=True and the mode='min'\n",
        "3. Define a variable `callbacks_list` that only contains the above defined checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORIi0MA86Ti8"
      },
      "source": [
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4nHWDmi6HdS"
      },
      "source": [
        "## Training our model\n",
        "- Call model.fit for X and y with 20 epochs, a batch size of 128 and the callbacks list you defined above.\n",
        "- BONUS: If you want to, try descreasing the batch size and increasing the epoch count to something like 64 and 50 - this can yield better results since there are more chances to learn.\n",
        "- Go get some coffee! ☕️☕️☕️"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jkzctIt6GwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9d7bd1-acda-49d3-f39f-d90a9a53eb84"
      },
      "source": [
        "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6835/6835 [==============================] - 428s 62ms/step - loss: 2.0756\n",
            "\n",
            "Epoch 00001: loss did not improve from 2.03973\n",
            "Epoch 2/50\n",
            "6835/6835 [==============================] - 422s 62ms/step - loss: 2.0202\n",
            "\n",
            "Epoch 00002: loss improved from 2.03973 to 2.02024, saving model to weights-improvement-02-2.0202.hdf5\n",
            "Epoch 3/50\n",
            "6835/6835 [==============================] - 423s 62ms/step - loss: 2.0668\n",
            "\n",
            "Epoch 00003: loss did not improve from 2.02024\n",
            "Epoch 4/50\n",
            "6835/6835 [==============================] - 430s 63ms/step - loss: 2.0101\n",
            "\n",
            "Epoch 00004: loss improved from 2.02024 to 2.01007, saving model to weights-improvement-04-2.0101.hdf5\n",
            "Epoch 5/50\n",
            "6835/6835 [==============================] - 433s 63ms/step - loss: 1.9045\n",
            "\n",
            "Epoch 00005: loss improved from 2.01007 to 1.90454, saving model to weights-improvement-05-1.9045.hdf5\n",
            "Epoch 6/50\n",
            "6835/6835 [==============================] - 433s 63ms/step - loss: 1.8837\n",
            "\n",
            "Epoch 00006: loss improved from 1.90454 to 1.88365, saving model to weights-improvement-06-1.8837.hdf5\n",
            "Epoch 7/50\n",
            "6835/6835 [==============================] - 429s 63ms/step - loss: 1.8577\n",
            "\n",
            "Epoch 00007: loss improved from 1.88365 to 1.85774, saving model to weights-improvement-07-1.8577.hdf5\n",
            "Epoch 8/50\n",
            "6835/6835 [==============================] - 423s 62ms/step - loss: 1.8401\n",
            "\n",
            "Epoch 00008: loss improved from 1.85774 to 1.84010, saving model to weights-improvement-08-1.8401.hdf5\n",
            "Epoch 9/50\n",
            "6835/6835 [==============================] - 422s 62ms/step - loss: 1.8238\n",
            "\n",
            "Epoch 00009: loss improved from 1.84010 to 1.82382, saving model to weights-improvement-09-1.8238.hdf5\n",
            "Epoch 10/50\n",
            "6835/6835 [==============================] - 423s 62ms/step - loss: 1.8072\n",
            "\n",
            "Epoch 00010: loss improved from 1.82382 to 1.80722, saving model to weights-improvement-10-1.8072.hdf5\n",
            "Epoch 11/50\n",
            "6835/6835 [==============================] - 423s 62ms/step - loss: 1.7957\n",
            "\n",
            "Epoch 00011: loss improved from 1.80722 to 1.79574, saving model to weights-improvement-11-1.7957.hdf5\n",
            "Epoch 12/50\n",
            "6835/6835 [==============================] - 421s 62ms/step - loss: 1.7802\n",
            "\n",
            "Epoch 00012: loss improved from 1.79574 to 1.78017, saving model to weights-improvement-12-1.7802.hdf5\n",
            "Epoch 13/50\n",
            "6835/6835 [==============================] - 422s 62ms/step - loss: 1.7675\n",
            "\n",
            "Epoch 00013: loss improved from 1.78017 to 1.76750, saving model to weights-improvement-13-1.7675.hdf5\n",
            "Epoch 14/50\n",
            "6835/6835 [==============================] - 424s 62ms/step - loss: 1.7557\n",
            "\n",
            "Epoch 00014: loss improved from 1.76750 to 1.75572, saving model to weights-improvement-14-1.7557.hdf5\n",
            "Epoch 15/50\n",
            "6835/6835 [==============================] - 422s 62ms/step - loss: 1.7426\n",
            "\n",
            "Epoch 00015: loss improved from 1.75572 to 1.74256, saving model to weights-improvement-15-1.7426.hdf5\n",
            "Epoch 16/50\n",
            "6835/6835 [==============================] - 424s 62ms/step - loss: 1.7347\n",
            "\n",
            "Epoch 00016: loss improved from 1.74256 to 1.73471, saving model to weights-improvement-16-1.7347.hdf5\n",
            "Epoch 17/50\n",
            "6835/6835 [==============================] - 421s 62ms/step - loss: 1.7243\n",
            "\n",
            "Epoch 00017: loss improved from 1.73471 to 1.72431, saving model to weights-improvement-17-1.7243.hdf5\n",
            "Epoch 18/50\n",
            "6835/6835 [==============================] - 424s 62ms/step - loss: 1.7147\n",
            "\n",
            "Epoch 00018: loss improved from 1.72431 to 1.71467, saving model to weights-improvement-18-1.7147.hdf5\n",
            "Epoch 19/50\n",
            "6835/6835 [==============================] - 423s 62ms/step - loss: 1.7071\n",
            "\n",
            "Epoch 00019: loss improved from 1.71467 to 1.70712, saving model to weights-improvement-19-1.7071.hdf5\n",
            "Epoch 20/50\n",
            "6835/6835 [==============================] - 424s 62ms/step - loss: 1.6971\n",
            "\n",
            "Epoch 00020: loss improved from 1.70712 to 1.69710, saving model to weights-improvement-20-1.6971.hdf5\n",
            "Epoch 21/50\n",
            "2268/6835 [========>.....................] - ETA: 4:44 - loss: 1.6836"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6Wj2MwF7ePy"
      },
      "source": [
        "## Using the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPxvJ_Ka8ABk"
      },
      "source": [
        "### Load the model with optimal weights\n",
        "1. Define a variable `filename` and assign it the name of your lowest loss checkpoint file\n",
        "2. Use `model.load_weigths` to load the weights from said file\n",
        "3. Compile the model as we did before (categorical crossentropy and adam)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-jHCnKy8Hx7"
      },
      "source": [
        "filename = \"weights-improvement-18-2.0397.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7ZmfjG-7inZ"
      },
      "source": [
        "### Create a reverse mapping from ints to chars\n",
        "Use the same strategy you had when creating the `characters_to_integers` dictionary to create a dictionary where the integers are the keys and the characters are the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9xUTS0K7gTN"
      },
      "source": [
        "integers_to_characters = dict((i, c) for i, c in enumerate(vocabulary))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryJwi_5V7pYN"
      },
      "source": [
        "### Generate some text\n",
        "1. Import the sys module\n",
        "2. Pick a random pattern from dataX to act as the seed and save it in a variable\n",
        "3. Print the pattern as characters using `integer_to_character`\n",
        "4. Loop 600 times\n",
        "  - Create a variable x that holds the `numpy.reshape`d pattern with the new shape `(1, length of pattern, 1)`\n",
        "  - Normalize x over `n_vocabulary`\n",
        "  - Use `model.predict` to make a prediction for x and save it in a variable\n",
        "  - Use `numpy.argmax` to choose the most probable result from the prediction and save it in a variable `result_index`\n",
        "  - Create a variable `result` containing the corresponding character for `result_index`\n",
        "  - Write that character to stdout using `sys.stdout.write`\n",
        "  - Append `result_index` to the pattern\n",
        "  - Drop the last character out of the pattern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6dcigQay_aX"
      },
      "source": [
        "import sys"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3UpFAZLslAI"
      },
      "source": [
        "dataX[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxc3Rfwm3Kpl",
        "outputId": "42527d82-0115-4c2b-8884-39d32127deda"
      },
      "source": [
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"seed:\")\n",
        "print(''.join([integers_to_characters[value] for value in pattern]))\n",
        "print(\"prediction:\")\n",
        "\n",
        "for i in range(100):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x/float(n_vocabulary)\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = integers_to_characters[index]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed:\n",
            "xistence and of its unspeakable torments, dared to hope for\n",
            "happiness, that while he accumulated wre\n",
            "prediction:\n",
            "tched the sass that i had been the same oooy and the sass oo the seman of the semeer of the same of "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}